# [AAAI2026] SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs

![](img/overview.jpg)

## Installation 


```bash
conda create -n SRD python=3.9 -y
conda activate SRD
pip install -r train/requirements.txt
pip install -r eval/requirements-eval.txt
mkdir checkpoints_remote
cd eval && pip install -v -e . 
```

## Train Backdoor Model
Run the following command to execute the backdoor attack method:
```bash
sh  run/run_train.sh
```
Select different backdoor attack methods by type using `bd_attack_type`. Only three attack methods are provided here for verification purposes: `BadNet`, `Blended`, and `TrojVLM`.

## Eval 
Run the following command to evaluate the `ASR` of the backdoor attack method.
```bash
sh  run/run_eval.sh
```
The results will be generated in `SRD/result` (including common metrics for captions and `ASR`). Three files, `img.pkl`, `sent.json`, and `img_id.json`, will be generated in the `SRD/eval/open_flamingo/eval/data` directory to assist with SFS evaluation.

## Eval_SFS
Run the following command to evaluate the SFS generated by the backdoor attack:
```bash
sh run/run_eval_SFS.sh
```
The path `name/type` is the folder where `img.pkl`, `sent.json`, and `img_id.json` are located.

A `SRD/eval/open_flamingo/eval/data/gt_sent.json` file is provided here as a demo of the gt sentences used for evaluation. If you need to replace other datasets, you need to regenerate the `gt_sent.json` file.

## SRD 
Run the following command to implement SRD defense:
```bash
sh  run/run_SRD.sh
```
Specific process description:

### 1. Initial SFS evaluation.

Run `SRD/train/pipeline/train/SFS_eval.py` to obtain the SFS results of the initial backdoor attack model and store them in the `save_data_path` path.

### 2. DQN training.

Run `SRD/train/pipeline/train/SRD_train.py` to train the DQN model.

- `--ppo_path`: Storage path for the trained DQN model;
- `--external_save_dir`: Path to the checkpoint files of the trained backdoor model;
- `--run_name`: Name of the trained backdoor model checkpoint;
- `--bd_attack_type`: Select the backdoor model;
- `--image_data_path`: SFS initial assessment storage file path.

### 3. Clean up backdoor data
Run `SRD/train/pipeline/train/SRD_clean_data.py` to clean the backdoor data.
- `--ppo_path`: Trained DQN model;
- `--clean_data_save`: Data storage path after SRD cleanup.

### 4. Merge data across multiple GPUs (skip this step for a single GPU)
Run `train/combine_data.py` to merge the data.

### 5. Refine-tune the backdoor model
Run `SRD/train/pipeline/train/SRD_fintune.py` to retrain the backdoor model and remove the backdoor from the model.
- `--bd_attack_type`: Select the backdoor model;
- `--run_name`: Backdoor model checkpoint that needs fine-tuning.


The `red_SRD.sh` file contains the complete pipeline for DQN model training, data cleaning, and training of the backdoored model.
