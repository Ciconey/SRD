# SRD: Reinforcement-Learned Semantic Perturbation for Backdoor Defense in VLMs

![](img/overview.jpg)

## Installation 


```bash
conda create -n SRD python=3.9 -y
conda activate SRD
pip install -r train/requirements.txt
pip install -r eval/requirements-eval.txt
mkdir checkpoints_remote
cd eval && pip install -v -e . 
```

## Train Backdoor Model
Run the following command to execute the backdoor attack method:
```bash
sh  run/run_train.sh
```
Select different backdoor attack methods by type using `bd_attack_type`. Only three attack methods are provided here for verification purposes: `BadNet`, `Blended`, and `TrojVLM`.

## Eval 
Run the following command to evaluate the `ASR` of the backdoor attack method.
```bash
sh  run/run_eval.sh
```
The results will be generated in `SRD/result` (including common metrics for captions and `ASR`). Three files, `img.pkl`, `sent.json`, and `img_id.json`, will be generated in the `SRD/eval/open_flamingo/eval/data` directory to assist with SFS evaluation.

## Eval_SFS
Run the following command to evaluate the SFS generated by the backdoor attack:
```bash
sh run/run_eval_SFS.sh
```
The path `name/type` is the folder where `img.pkl`, `sent.json`, and `img_id.json` are located.

A `SRD/eval/open_flamingo/eval/data/gt_sent.json` file is provided here as a demo of the gt sentences used for evaluation. If you need to replace other datasets, you need to regenerate the `gt_sent.json` file.

## SRD 
Run the following command to implement SRD defense:
```bash
sh  run/run_SRD.sh
```
Specific process description:

### 1. Initial SFS evaluation.

Run `SRD/train/pipeline/train/SFS_eval.py` to obtain the SFS results of the initial backdoor attack model and store them in the `save_data_path` path.

### 2. DQN training.

Run `SRD/train/pipeline/train/SRD_train.py` to train the DQN model.

- `--ppo_path`: Storage path for the trained DQN model;
- `--external_save_dir`: Path to the checkpoint files of the trained backdoor model;
- `--run_name`: Name of the trained backdoor model checkpoint;
- `--bd_attack_type`: Select the backdoor model;
- `--image_data_path`: SFS initial assessment storage file path.

### 3. Clean up backdoor data
Run `SRD/train/pipeline/train/SRD_clean_data.py` to clean the backdoor data.
- `--ppo_path`: Trained DQN model;
- `--clean_data_save`: Data storage path after SRD cleanup.

### 4. Merge data across multiple GPUs (skip this step for a single GPU)
Run `train/combine_data.py` to merge the data.

### 5. Refine-tune the backdoor model
Run `SRD/train/pipeline/train/SRD_fintune.py` to retrain the backdoor model and remove the backdoor from the model.
- `--bd_attack_type`: Select the backdoor model;
- `--run_name`: Backdoor model checkpoint that needs fine-tuning.


The `red_SRD.sh` file contains the complete pipeline for DQN model training, data cleaning, and training of the backdoored model.

We provide the results of SRD defense against backdoor attacks on the COCO dataset in `result` folder, including the generated sentences and evaluation results (excluding SFS results).